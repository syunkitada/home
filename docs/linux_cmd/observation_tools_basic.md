# Observability tools basic

PC のリソースの利用状況や正常性、エラーをチェックするためのコマンド集です。

## sysstat のインストール

```bash
$ sudo yum install sysstat
```

## uptime

```bash
# 現在の時刻 up 起動時間, ログインユーザ数 user, load avelage: 1分, 5分, 30分
$ uptime
23:51:26 up 21:31,  1 user,  load average: 30.02, 26.43, 19.02
```

- 現在の時刻がずれている場合
  date でタイムゾーンをチェック

```bash
$ date
2016年  2月 28日 日曜日 11:55:54 JST
```

ntp で時刻同期をチェック

```bash
$ ntpq -p
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 ntp.kiba.net    189.130.221.188  2 u   31   64    1   24.292   -0.229   0.000
 ec2-54-64-6-78. 133.243.238.164  2 u   31   64    1   17.889    0.627   0.000
```

ntp の設定をチェック

```bash
$ vim -R /etc/ntp.conf
```

- 起動時間が短い場合
  リブートした覚えがないのに、これが短い場合 PC が何かの原因でリブートした可能性がある

- load avelage
  load avelage とは、現在 CPU が実行しているタスク数のこと。
  つまり、CPU のスレッド数よりも大きい場合は、処理が間に合っていないことになる。

これには、割り込み不可能な IO でブロックされているプロセスも含まれているので、ディスク IO が間に合っていない場合などによくこの値が高くなる。

また、load avelage が、1 分間、5 分間、15 分間の指数移動平均で表示されるので、負荷が時間経過とともにどのように変化したかがわかる。

15 分間の load average より、5, 1 分間の load average が非常に大きい場合、今現在なにかが起きている可能性がある。
また、5, 1 分間の load average が非常に少ない場合、今現在はなにも起きていないが、5 ～ 15 分前になにか起きていた可能性がある。

## dmesg | less

```bash
$ dmesg | less

[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0
[...]
[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child
[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB
[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.
```

oom-killer と TCP のリクエストのドロップなど、エラーを含むシステムの情報を得ることができます。
なにか起きてると思ったらすぐにチェックすべき項目です。

## vmstat 1 -t

```bash
$ vmstat 1 -t
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- -----timestamp-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st                 UTC
 2  0      0 259516    888 1476192    0    0    84  1514 1191 2660 10  4 83  1  2 2017-03-04 03:35:53
 5  0      0 259032    888 1476224    0    0     0    19 1015 2444  7  3 90  0  0 2017-03-04 03:35:54
 0  0      0 259268    888 1476228    0    0     0    25 1253 2774 16  8 69  0  6 2017-03-04 03:35:55
 0  0      0 259236    888 1476236    0    0     0    46  993 2469  6  1 93  0  0 2017-03-04 03:35:56
 0  0      0 259004    888 1476252    0    0     0    27 1168 2941  5  5 88  0  2 2017-03-04 03:35:57
^C
```

1 秒間ごとに仮想メモリの統計を表示します。
一行目はシステム起動時からの平均。

r : CPU で実行中および順番を待っているプロセスの数。これは I/O を含んでいないので、CPU の飽和状態を見るのに、ロードアベレージよりも良いシグナルになります。言い換えると、"r"の値が CPU 数よりも多ければ飽和状態ということです。

free : キロバイトでの空きメモリー量。数えられないぐらいの桁数が表示されていたら、十分なメモリーがあります。7 番目に出てくる free -m コマンドは、空きメモリのより詳しい説明を表示してくれます。

si, so : スワップインとスワップアウト。ゼロでない値があれば、メモリ不足。

us, sy, id, wa, st : CPU 時間の内訳で、すべての CPU に対する平均値。それぞれ、ユーザ時間、システム(カーネル)時間、アイドル時間、I/O 待ち時間、steal された時間(他のゲストマシンや、Xen の場合ゲストの分離されたドライバードメインによる steal)。

CPU 時間の内訳で、user と system 時間を足すことで CPU がビジーかどうか確認できるでしょう。I/O 待ちが一定の数値を示しているならディスクがボトルネックです。この時、タスクはディスク I/O 待ちでブロックされてしまうため、CPU はアイドル状態になってしまっています。従って、I/O 待ちは CPU アイドル時間の別の形と考えられ、なぜアイドルなのかを調べる手がかりになり得ます。

システム時間は、I/O 処理に必要です。20%を超えるような高いシステム時間は、詳しく調べる必要があると言えるでしょう。おそらくカーネルが I/O を効率よく処理できていない状態です。

上の例では、CPU 時間はほとんどユーザレベルになっており、つまりアプリケーションレベルが使用していることを示しています。CPU は平均 90%以上使用されています。これは必ずしも問題とは言えず、「r」列で飽和状態の程度を調べましょう。

## mpstat -P ALL 1

```bash
$ mpstat -P ALL 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)

07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle
07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78
07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99
07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00
07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00
07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03
[...]
```

CPU ごとの CPU 時間の内訳を表示します。

top 中に 1 でも見れる。

## pidstat 1

```bash
$ pidstat 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)

07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0
07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave
07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java
07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java
07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java
07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat

07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave
07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java
07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java
07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass
07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat
^C
```

pidstat は、top のプロセスごとの概要とも言えるものですが、スクリーンをクリアする代わりに連続して概要を表示します。これは、時系列でのパターンを見るのに便利で、見たものを調査の記録にとっておく(コピペ)のにもよいでしょう。

上の例では、2 つの java プロセスが CPU を消費している原因だとわかります。%CPU 列は全 CPU に対する使用率ですが、1591%という表示から java プロセスがほぼ 16CPU 分を使用していると分かります。

## iostat -xz 1

```bash
$ iostat -xz 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          73.96    0.00    3.73    0.03    0.06   22.21

Device:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
xvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09
xvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25
xvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26
dm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04
dm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00
dm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03
[...]
^C
```

ブロックデバイス(ディスク)に適用されるワークロードと、その結果のパフォーマンスの両方を理解出来る素晴らしいツールです。見方は以下の通り。

r/s, w/s, rkB/s, wkB/s : 秒間にデバイスに送られた読み出し回数、書き込み回数、読み出しキロバイト、書き込みキロバイトを表します。ワークロードの特徴をつかむのに使いましょう。パフォーマンスの問題はたいていの場合、単に過剰な負荷がかけられていることが原因です。
await : I/O の平均時間のミリ秒表示。これは、アプリケーションが待たされた時間で、キューに入っていた時間と実際のサービス時間の両方を含んでいます。期待した平均時間より長い場合、デバイスが飽和状態か、デバイス自体に問題がある可能性があります。

avgqu-sz : デバイスに対して発行されたリクエストの平均数。(複数のバックエンドディスクの前に立つ仮想デバイスは特に、デバイスはリクエストを通常は並行に処理しますが)1 より大きい値は、飽和状態を表します。

%util : デバイスの使用率。これは、実際にはビジーな割合で、デバイスが仕事をした時間を秒ごとに出したものです。デバイスにもよりますが、一般的に 60%より大きい値はパフォーマンスの劣化(await にも表れます)につながります。100％に近い値は通常、飽和状態を意味します。

ストレージデバイスがたくさんのバックエンドディスクを持つ論理ディスクデバイスの場合、使用率が 100%ということは、なんらかの I/O が 100%の時間処理され続けているということである一方で、バックエンドディスクは飽和状態からは程遠い可能性が高く、もっと多くの処理が可能なはずです。

頭にとどめておきたいのは、ディスク I/O のパフォーマンスが悪いことは、必ずしもアプリケーションの問題になるわけではないということです。I/O を非同期に実行するために、多くのテクニックがよく使われるので、アプリケーションはブロックされず、レイテンシも直接は影響してこないのです(例、読み出しには先読み、書き込みにはバッファリング)。

## sar -n DEV 1

```bash
$ sar -n DEV 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86_64_    (32 CPU)

12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00
12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00
12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00

12:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00
12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00
12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
^C
```

このツールで、ワークロードの目安になるネットワークインターフェースのスループットである rxkB/s と txkB/s を調べましょう。また、なんらかの制限に達していないかどうかも確認しましょう。上の例では、eth0 が 22Mbytes/s、つまり 176Mbits/sec を受信しています(つまり 1Gbit/sec の制限にひっかかっています)。

このバージョンでは、デバイスの使用率(全二重での上り下り両方での最大値)として%ifutil も表示されていて、これは Brendan の nicstat ツールでの計測のためにも使います。ただし、nicstat と同じく、なかなか正しい値を示してはくれず、上の例(0.00)のようにちゃんと動いていないように見える場合が多いようです。

## sar -n TCP,ETCP 1

```bash
$ sar -n TCP,ETCP 1
Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)

12:17:19 AM  active/s passive/s    iseg/s    oseg/s
12:17:20 AM      1.00      0.00  10233.00  18846.00

12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
12:17:20 AM      0.00      0.00      0.00      0.00      0.00

12:17:20 AM  active/s passive/s    iseg/s    oseg/s
12:17:21 AM      1.00      0.00   8359.00   6039.00

12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s
12:17:21 AM      0.00      0.00      0.00      0.00      0.00
^C
```

これは、いくつかの重要な TCP 関連メトリクスの概要です。以下を含んでいます。

active/s : 1 秒あたりのローカルから接続を開始した TCP コネクション数(例、connect()による接続)
passive/s : 1 秒あたりのリモートから接続を開始した TCP コネクション数(例、accept()による接続)
retrans/s : 1 秒あたりの TCP 再送数
active/s と passive/s の数は、それぞれ新しく受け入れたコネクション数と新しく下流に向けて張ったコネクション数で、サーバーの負荷をおおまかに把握するのに便利です。active を外向き、passive を内向きと考えるのに便利ですが、厳密に正しいとは言えません(ローカルホストからローカルホストへのコネクションなどを考慮する必要があるなど)。

再送はネットワークあるいはサーバーの問題のサインです。ネットワークの信頼性が低い(例、パブリックなインターネット)か、サーバーが過負荷でパケットをドロップしているかでしょう。上の例では、1 秒に 1 TCP コネクションしか生成されていません。

## top

```bash
$ top
top - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92
Tasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie
%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers
KiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem

   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java
  4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave
 66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top
  5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java
  4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java
     1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init
     2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd
     3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0
     5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H
     6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0
     8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched

```

top コマンドには、これより前に見てきたメトリクスの多くが含まれています。負荷が変わりやすいことを示してくれるここまで見てきたコマンドと違って、ざっくりと確認したいときには便利でしょう。

top の良くないところとしては、時間を追って表れるパターンをつかみにくいことで、これらは連続して出力を出してくれる vmstat や pidstat などの方がよりはっきりと分かります。間欠的に現れる現象についても、出力を素早く停止(Ctrl-S で一時停止、Ctrl-S で再開)できないとスクリーンがクリアされて消えてしまいます。

## ps

### ps -eF f

```bash
$ ps -eF f
UID        PID  PPID  C    SZ   RSS PSR STIME TTY      STAT   TIME CMD
root         2     0  0     0     0   0 08:46 ?        S      0:00 [kthreadd]
root         3     2  0     0     0   0 08:46 ?        S      0:00  \_ [ksoftirqd/0]
root         6     2  0     0     0   0 08:46 ?        S      0:00  \_ [kworker/u2:0]
root         7     2  0     0     0   0 08:46 ?        S      0:00  \_ [migration/0]
root         8     2  0     0     0   0 08:46 ?        S      0:00  \_ [rcu_bh]
...
root     12009     1  0 56550  5152   0 08:48 ?        Ss     0:00 /usr/sbin/httpd -DFOREGROUND
apache   12010 12009  0 56550  3000   0 08:48 ?        S      0:00  \_ /usr/sbin/httpd -DFOREGROUND
apache   12011 12009  0 56550  3000   0 08:48 ?        S      0:00  \_ /usr/sbin/httpd -DFOREGROUND
apache   12012 12009  0 56550  3000   0 08:48 ?        S      0:00  \_ /usr/sbin/httpd -DFOREGROUND
apache   12013 12009  0 56550  3000   0 08:48 ?        S      0:00  \_ /usr/sbin/httpd -DFOREGROUND
```

### watch -n 1 -d "ps auxw | grep ' R' | grep -v grep"

```bash
$ watch -n 1 -d "ps auxw | grep ' R' | grep -v grep"
root        10  0.0  0.0      0     0 ?        R    01:56   0:02 [rcu_sched]
root       276  0.0  0.0      0     0 ?        R    01:56   0:01 [xfsaild/sda1]
...

$ watch -n 1 -d "ps auxw | grep ' D' | grep -v grep"
...
```

top コマンドでもある程度のプロセス状態を見ることは可能であるが、より正確にプロセスの状態を見たい場合は ps を利用するとよい。
例えば、実行キューが詰まっている場合は R で grep したり、IO が詰まっている場合は D で grep したりすると、どのプロセスが悪さをしているかがわかる。

ステータス

- R Run TASK_RUNNING 実行可能な状態。CPU が空きさえすれば、いつでも実行可能な状態。
- S Sleep TASK_INTERRUPTIBLE 割り込み可能な待ち状態。おもに復帰時間が予測不能な長時間の待ち状態。スリープやユーザからの入力待ちなど。
- D Disk Sleep TASK_UNINTERRUPTIBLE 割り込み不可能な待ち状態。おもに短時間で復帰する場合の待ち状態。ディスクの入出力待ち。
- T Stopped TASK_STOPPED サスペンドシグナルを送られて実行中断になった状態。リジュームされるまでスケジューリングされない。
- Z Zombie TASK_ZOMBIE ゾンビ状態。子プロセスが exit して親プロセスにリープされるまでの状態。

### ps -eo [fields]

- 表示フィールドをカスタマイズする

```bash
$ ps -eo user,sz,rss,minflt,majflt,pcpu,args
```

## /proc/interrupts

```
$ cat /proc/interrupts

$ watch -n 1 -d "cat /proc/interrupts | egrep 'RES|CAL|TLB'"
```

- /proc/interrupts で割り込みを表示できる
- 割り込みを少なくするようにチューニングすることはパフォーマンス向上につながる
- 逆に、割り込みが多すぎるとパケットや、プロセスのつまりの原因になる

## 参考

- [6 万ミリ秒でできる Linux パフォーマンス分析]: https://yakst.com/ja/posts/3601?platform=hootsuite
  [原文]: http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html
- [Linux Performance Tools]: http://techblog.netflix.com/2015/08/netflix-at-velocity-2015-linux.html
