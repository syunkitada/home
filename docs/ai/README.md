# AI

## 用語

- AI(Artificial Intelligence) 人工知能
  - AIは、コンピュータが人間のように学習、推論、問題解決を行う技術やシステムを指します。
- 機械学習
  - 機械学習は、AIの一分野で、コンピュータがデータからパターンを学習し、予測や分類を行う技術です。
  - 機械学習の種類
    - 教師あり学習
      - ラベル付きデータを用いてモデルを学習させる方法です。
      - 例: 画像認識、スパムメール分類。
    - 教師なし学習
      - ラベルなしデータを用いてデータの構造を学習する方法です。
      - 例: クラスタリング、次元削減。
    - 強化学習
      - エージェントが環境と相互作用し、報酬を最大化するための行動を学習する方法です。
      - 例: ゲームプレイ、ロボット制御。
    - ディープラーニング(深層学習)
      - ニューラルネットワークを用いて複雑なデータの特徴を自動的に学習する方法です。
      - 例: 画像認識、自然言語処理。

## 2012年からのAIの歴史

- 2012年
  - CNN(Convolutional Neural Network)を用いたAlexNetがImageNetコンペティションで優勝し、既存アルゴリズムの制度を大きく上回りました。
  - この画像認識の分野での成功が、ディープラーニングのブレイクスルーとなり、以降の研究や応用が加速しました。
- 2016年-2017年
  - Google翻訳での利用や、DeepLのサービス開始など、翻訳分野でのディープラーニングの応用が広がりました。
  - Transformerの論文が発表され、自然言語処理の分野で大きな影響を与えました。
    - Transformer では Attention という新しい構造が導入されています。
    - Attention は入力された文章と解くべきタスクに対して、文のどの単語が重要か、どの単語に注目すべきかを決める仕組みです。
    - これにより、文章が長くなってもどこに注目すれば良いかがわかり、精度が落ちないようになりました。
  - Transformer と同時期に自己教師あり学習が注目されるようになりました。
    - 自己教師あり学習は、ラベルなしデータを用いてモデルを事前に学習させる手法です。
    - これにより、大量のテキストデータから汎用的な知識を学習できるようになりました。
- 2018年
  - 2018年にTransformerと自己教師あり学習を組み合わせたGPT-1(Generative Pre-trained Transformer: OpenAI)やBERT(Bidirectional Encoder Representations from Transformers: Google)が登場しました。
  - このGPT-1やBERTがLLM(Large Language Model)の基礎となり、自然言語処理の分野で大きな進展をもたらしました。
  - GPT-1とBERTは事前学習モデルです。
    - 事前学習モデルは、特定のタスクを解くための学習はせずに、汎用的な知識を事前に学習します。
    - その後、ファインチューニングと呼ばれる手法で、特定のタスクに適応させることができます。
  - GPTやBERTは、後に続く単語の予測問題と穴埋め問題で学習しており、文脈理解や単語の関係性といった自然言語の特徴を捉えることができるようになりました。
- 2019年
  - OpenAIが、"Scaling Laws of Neural Language Models"という論文を発表しました。
    - この論文では、マシンリソース、データセットのサイズ、モデルのパラメータ数を増やすことで、モデルの性能が向上することが示されました。
  - つまるところ、お金をかければLLMの性能を向上させることができるとわかり、AIへの投資も加速し、モデルの大規模化も進みました。
- 2022年
  - GPT-3.5が登場し、ChatGPTが公開され、対話が可能な文章の生成としてLLMの実用化が進みました。
  - ChatGPTを皮切りに、様々な分野でのLLMを利用したLLMアプリケーションが登場し始めました。
    - Stable Diffusionが公開され、画像生成AIの分野でも大きな進展がありました。
    - GitHub Copilotが公開され、プログラミング支援の分野でもAIの活用が進みました。
- 2023年
  - 各社がLLMを開発し、それらを利用したLLMアプリケーションが次々と登場しました。
  - 代表的なLLMには以下のものがあります。
    - GPT-4: OpenAI
      - GPT-4は、GPT-3.5の後継モデルで、より高精度な自然言語処理が可能です。
      - テキストデータだけでなく、画像や音声などのマルチモーダルデータも扱えるようになりました。
    - PaLM2: Google
    - LaMDA2: Google
    - Gemini(旧Bard): Google
      - Geminiは、Googleの次世代LLMで、テキスト、画像、音声など、さまざまな形式のデータを同時に処理できるマルチモーダルモデルです。
    - LLaMA2: Meta
    - Claude2.1: Anthropic
    - OpenCALM: サイバーエージェント
    - Alpaca 7B: スタンフォード大学
- 2024年
  - "Textbooks Are All You Need"という論文が発表されました。
    - この論文では、高品質なデータセットがあれば、1/10のモデルサイズ、1/100のデータでも性能が向上することが示されました。
  - MCP(Model Context Protocol)という新しいプロトコルがAnthropicによって提案されました。
    - MCPは、LLMアプリケーションが外部のAPIと連携するためのプロトコルで、LLMアプリケーションは外部のデータやサービスを利用して、より高度なタスクを実行できるようになります。
    - インターネット検索、GitHub、Slack、Wiki など様々なデータソースのMCPサーバーを提供することで、LLMアプリケーションはこれらのサービスと連携することができます。
- 2025年
  - 様々なAIエージェントが登場し、本格的に活用され始めました。
    - AIエージェントは、LLMを利用して自律的にタスクを実行するAIシステムです。
    - AIエージェントは、LLMを利用して自然言語での指示を理解し、外部のAPIやサービスと連携してタスクを実行します。
    - AIエージェントは、LLMアプリケーションの進化形として、より高度なタスクを自律的に実行できるようになります。

## プログラミング分野でのAI活用の歴史

- 2022年
  - GitHub Copilot リリース
    - GitHub Copilotは、OpenAIのCodexを利用してコード補完や提案を行うツールです。
- 2023年
  - Cursor リリース
    - Cursorは、VS Codeをフォークして開発されたAI支援機能を搭載したコードエディタです。
- 2025年
  - 4月: Cognition AIが、Devinをリリース
    - Devinは、AIエージェントを利用してプログラミング支援を行うツールです。
  - 5月: Anthropicが、Claude Codeをリリース
    - Claude Codeは、AIエージェントを利用してプログラミング支援を行うツールです。
  - 5月: Microsoft/GitHubが、GitHub Copilot Agentリリース
    - GitHub Copilot Agentは、GitHub CopilotのAIエージェント版で、より高度なプログラミング支援を行います。

## 参考

- [2024/03/29 LLMの現在](https://speakerdeck.com/pfn/llm-no-genzai-imos)
